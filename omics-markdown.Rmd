---
title: "â€˜Omics Project"
author: "Aeriel Belk, Amanda Walz, Rebecca Cheek, Kyle Root"
date: "12/5/2018"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

This is an R-markdown we can use!!

Steps: 

1. import and early explore data
2. then, see what analyses we can do

```{r data}
library(readr)
library(stringr)
wn_meta<- read.csv("metadata/metadata.csv")
```
 

Ideas for us to look at. 
Aeriel: Build a phylogenetic tree using Bioconductor(phyloseq) to look at divergence and host species
Kyle:Compare genetic viersity between host species and vecotr species
Amanda: sf plot to use lat-long data and group by infected species by region by season
Rebecca: Landscape genetics approach to look at how the urban vs. rural affects genetic structure or rate of gene flow (see https://doi.org/10.1111/mec.14783). Maybe use popualtion density in each county as a proxy for urbanization.  


Do some analysis of the metadata:

 - species 
 - latitude/longitude
 - distribution over counties
 - sequence similarities/ density by region
 
```{r libraries, message=FALSE, warning=FALSE}
library(seqinr)
library(purrr)
library(dplyr)
library(readr)
library(phyloseq)
library(stringr)
library(tidyr)
library(lubridate)
library(forcats)
library(tigris)
library(knitr)
library(ggplot2)
library(sf)
library(ggdendro)
library(leaflet)
library(viridisLite)
library(RColorBrewer)

# if (!requireNamespace("BiocManager", quietly = TRUE))
#    install.packages("BiocManager")
# BiocManager::install("Biostrings", versilibrary(devtools) on = "3.8"

library(Biostrings)

# if (!requireNamespace("BiocManager", quietly=TRUE))
# install.packages("BiocManager")
# BiocManager::install("msa")

library(msa)

# if (!requireNamespace("BiocManager", quietly = TRUE))
#     install.packages("BiocManager")
# BiocManager::install("DECIPHER", version = "3.8")
library(DECIPHER)

            
```

``` {r metadata formatting}
metadata_url <- paste0("https://raw.githubusercontent.com/aeriel-belk/NSCI535-westnile-omics/master/metadata/metadata.csv")

metadataframe <- read_csv('metadata/metadata.csv')
metadataframe <- metadataframe %>% 
  rename_all(tolower)

```


steps to read in:
1) list.files with full names option to get names of all files in folder, save in object (char vector)
2) pipe that vector into map function that does read.fasta (play around with just the first file first)
3) result should be a long list

seqinr -> read.fasta

```{r read-in}
#1) list files into vector
files <- list.files(path = 'consensus_sequences', full.names = TRUE)

#2) make map function to read in fasta files
#fasta <- map(.x = files, .f = read.fasta, 
#             as.string = TRUE, forceDNAtolower = FALSE)

fasta2 <- readDNAStringSet(files, format="fasta", nrec=-1L, skip=0L, seek.first.rec=FALSE, use.names=TRUE)

writeXStringSet(fasta2, 'consensus-seqs.fna')
#writeXStringSet(LargeDNAStringSet, 'fname.fa')
#write.fasta(sequences, names, file.out, open = "w", nbchar = 60, as.string = FALSE)

```

*******************************************************************************

### Align Sequences
  
Using BioStrings (https://bioconductor.org/packages/release/bioc/html/Biostrings.html) to align sequences so we can compare across samples. Plan is to align, then try to cluster the sequences into groups based on similarity. This will allow us to build trees, which we can try to apply to Amanda and Rebecca's analyses of season and population, as well as host species.
  
  After getting it important and *roughly* in a usable format, I tried doing some alignment and clustering with the biostrings package
  
```{r biostring, eval=FALSE}
#sdist <- stringDist(as(fasta2,"DNAStringSet"), method="hamming")
#clust <- hclust(fasta2, method = "single")

#sdist <- stringDist()

### 11-28-18, ADB ###

aligned <- DNAMultipleAlignment(fasta2)
# unequal number of characters error

aligned2 <- readDNAMultipleAlignment('consensus_sequences', 'fasta')
# got output with 0 rows, but a start!
## This was all bad.

## Starting from Rebecca's work here ##
clean_seq <- readDNAStringSet("fasta/clear_wnv_clean.fas")

# trying clustering on unmasked
sdist <- stringDist(as(clean_seq,"DNAStringSet"), method="hamming")
clust <- hclust(sdist, method = "ward.D2")

clust_df <- data_frame(sample = metadataframe, cluster = clust)


## other ggplot method
dend <- as.dendrogram(clust)
dend_data <- dendro_data(dend, type = 'rectangle')
  
unique(metadataframe$species_type)

colors <- metadataframe %>% 
  mutate(color = species_type %in% 'corvid' )

colors <- metadataframe$color

ggplot(segment(dend_data)) +
  geom_segment(aes(x = x, y = y, xend = xend, yend = yend)) +
  coord_flip() +
  scale_y_reverse(expand = c(0.2, 0)) +
  theme_dendro()


## Try without ggplot
#install.packages('dendextend')
library(dendextend)

dend <- assign_values_to_leaves_edgePar(dend, value = colors, edgePar = "col") # add the colors.
#dend <- assign_values_to_leaves_edgePar(dend, value = 3, edgePar = "lwd") # make the lines thick
plot(dend, leaflab = 'none', horiz = TRUE, axes = FALSE)



```
  
  
********************************************************************************
  
*Amanda tenative plan to make an interactive map characterizing WNV infections by season, species*

```{r mapped_plot}

#Tidy data for county map with infections by season
ca_wnv <- metadataframe %>% 
  select("species", "collection date",
           "county", "latitude", "longitude") %>% 
  rename_all(funs(str_replace(., "\\s", "_"))) %>% 
  separate(col = collection_date, 
           into = c("month", "day", "year"),
           sep = "/") %>% 
  mutate(month = factor(month),
         season = fct_collapse(month,
               winter = c("12", "1", "2"),
               spring = c("3", "4", "5"),
               summer = c("6", "7", "8"),
               fall = c("9", "10", "11"))) %>% 
  mutate(latitude = as.numeric(latitude)) %>% 
  mutate(longitude = as.numeric(longitude)) %>% 
  na.omit() %>% 
  mutate(species = fct_lump(species,
                                n = 4))

species_summary <- ca_wnv %>% 
  group_by(species) %>% 
  summarize(species_no = n())
season_summary <- ca_wnv %>% 
  group_by(season) %>% 
  summarize(no_infections = n())
kable(species_summary,
      col.names = c("Species", "Number Infected"))
kable(season_summary,
      col.names = c("Season", "Number of Cases"))

#Creating CA sf boundaries
ca_wnv_sf <- st_as_sf(ca_wnv, 
                      coords = c("longitude", "latitude"),
                      crs = 4269)
ca_counties <- counties(state = 06, cb = TRUE, class = "sf")
co_tracts <- tracts(state = 06, cb = TRUE, class = "sf")

#Plot to show relation of infections to water area 
ggplot() +
  geom_sf(data = ca_counties, aes(fill = AWATER),
          alpha = 0.5) +
  geom_sf(data = ca_wnv_sf, aes(color = season,
                                shape = species)) +
  scale_fill_viridis_c(name = "Area of Water") +
  facet_wrap(.~season) +
  ggtitle("California West Nile Virus Infections") +
  xlab("Longitude") +
  ylab("Latitude") +
  scale_x_continuous()

#Leaflet graph
popup_info <- paste0("<b>Species:</b>  ", 
                                  ca_wnv$species, "<br/>",
                                  "<b>Season:</b>  ",
                                  ca_wnv$season, "<br/>",
                                  "<b>Year:</b>  ",
                                  ca_wnv$year)
season_pallet <- colorFactor(brewer.pal(4, "Dark2"),
                             ca_wnv$season)

leaflet() %>% 
  addProviderTiles("Esri.NatGeoWorldMap") %>% 
  addPolygons(data = ca_counties,
              group = "tracts") %>% 
  addCircleMarkers(data = ca_wnv, radius = 2,
                   lng = ~ longitude, lat = ~ latitude,
                   popup = popup_info,
                   color = season_pallet(ca_wnv$season),
                   group = "infections",
                   clusterOptions = markerClusterOptions()) %>%
  addLayersControl(baseGroups = c("Base Map"),
                   overlayGroups = c("Tracts", "Infections"))

```
  
********************************************************************************
*Rebecca making a map to look at urbaization and WNV genetic structure*

Trying to relate the virus's genetic structure to urbanization. Since the data doesn't provide a real gradient of 'urbanization' we will use human popualtion density as a proxy
```{r}
####Human population density map bit##
#### Rebecca trying to make life easier by using census data per county as a proxy for urbanization
library(tidyverse)
library(tidycensus) ##tidycensus package
library(leaflet)
library(stringr)
library(sf)
library(dplyr)
library(adegenet)
library(pegas)
library(Biostrings)
library(dplyr)
library(seqinr)
library(ape)
library(ShortRead)
library(ggplot2)
library(ggmap)
library(maps)
library(mapdata)
library(tigris)
library(adegenet)
library(spdep)
library(dartR) ## One good lesson. If you develope a package be sure to include all the dependencies in the installation you twat
library(csv)
library(DECIPHER)

census_api_key("a22c251a387f5312b9e5c2e5ad21494088e984f6")

ca_pop <- get_acs(geography = "county", 
               
                     state = "CA",
                     geometry = TRUE) 

ca_pop


pal <- colorQuantile(palette = "viridis", domain = ca_pop$estimate, n = 5)

ca_density <- ca_pop %>%
    st_transform(crs = "+init=epsg:4326") %>%
    leaflet(width = "100%") %>%
    addProviderTiles(provider = "CartoDB.Positron") %>%
    addPolygons(popup = ~ str_extract(NAME, "^([^,]*)"),
                stroke = FALSE,
                smoothFactor = 0,
                fillOpacity = 0.7,
                color = ~ pal(estimate)) %>%
    addLegend("bottomright", 
              pal = pal, 
              values = ~ estimate,
              title = "Population Percentiles",
              opacity = 1)

ca_density



#### County map of top three sampling counties


ca_base <- counties(state= c("CA"), cb= T, class= "sf")
kern <- ca_base %>% 
  filter(NAME == "Kern")

kern_county <- geom_sf(data = Kern, fill="brown1", alpha=.35)

San_Diego <- ca_base %>% 
  filter(NAME == "San Diego")
San_Diego_county <- geom_sf(data = San_Diego, fill="darkorchid1", alpha=.35)

Sacramento <- ca_base %>% 
  filter( NAME=="Sacramento")
Sacramento_county <- geom_sf(data = Sacramento, fill="cyan3", alpha=.35)

county_map <- ggplot() + 
  geom_sf(data = ca_base, color="grey")+
  theme_void() +
  Sacramento_county +
  kern_county +
  San_Diego_county
  
county_map


######################################################

#Genomics bit#
#read in the data using bioStrings package
cons_seq <- readDNAStringSet("consensus-seqs.fna")

#number of occurances of each character
alphabetFrequency(cons_seq, baseOnly=TRUE, collapse=TRUE) #total 
#      A       C       G       T   other 
#1847658 1495638 1935723 1460705  342960 


freqs <- alphabetFrequency(DNAStringSet(cons_seq[!is.na(cons_seq)]), baseOnly=TRUE) #by sequence
head(freqs)


##DECIPHER package for aligning raw sequences to eachother based on similarity
## Note- don't have to run this code, Rebecca made a 

##DECIPHER package for sequence alignment  
library(DECIPHER)
dna <- unique(cons_seq) # the unique input sequences
index <- match(cons_seq, dna) # de-replication index
<<<<<<< HEAD
aligned <- AlignSeqs(dna) # align the sequences directly without translation
aligned_seq <- aligned[index]
names(aligned_seq) <- names(cons_seq) # the re-replicated alignment
aligned_seq <- AlignSeqs(cons_seq) # align the sequences directly without translation
aligned_seq <- U_DNA[index]
names(cons_seq) <- names(cons_seq) # the re-replicated alignment

head(aligned_seq)

#Post processing 
BrowseSeqs(aligned_seq, highlight=0) #visualize sequences in internet browser

wnv_adjusted <- AdjustAlignment(aligned_seq)  #fixes any "obvious mistakes" 

writeXStringSet(wnv_adjusted,file="wnv_adjusted.fas",format="fasta")

#use shortread to trim off the ends of the data where there are a lot of missing values 
wnv_clean <- DNAStringSet(substr(wnv_adjusted,31,10963))
wnv_clean
writeXStringSet(wnv_clean,file="wnv_clean.fas",format="fasta")

#use pegas to build a haplotype network
input <- "wnv_clean.fas"
fasta.read <- ape::read.dna(input, format='fasta')
distance_wnv <- dist.dna(fasta.read)
wnv_hap <- pegas::haplotype(fasta.read)
wnv_hap <- sort(wnv_hap, what = "label")
(net <- pegas::haploNet(wnv_hap))
ind.hap <-with(stack(setNames(attr(wnv_hap, "index"), rownames(wnv_hap))),
table(hap=ind, pop=rownames(fasta.read)[values])
)
plot(net, size=attr(net, "freq"), scale.ratio=0.2, pie=ind.hap)
legend(-8, 0, colnames(ind.hap), col=rainbow(ncol(ind.hap)), pch=19, ncol=2)
```

********************************************************************************
*Kyle comparing differences in metadata*
```{r}

#check out clean data set
clean_seq <- readDNAStringSet("fasta/clear_wnv_clean.fas")
length(clean_seq[[1]]) #length of first sequence in the multi FASTA file

#number of occurances of each character
alphabetFrequency(clean_seq, baseOnly=TRUE, collapse=TRUE) #total 
#      A       C       G       T   other 
#1731156 1401504 1814384 1368161  146198  
freqs_clean <- alphabetFrequency(DNAStringSet(clean_seq[!is.na(clean_seq)]), baseOnly=TRUE) # number of bases by sequence 
head(freqs_clean)
BrowseSeqs(clean_seq, highlight=0) #visualize sequences in internet browser
 

clean_wnv_input <- "fasta/clear_wnv_clean.fas"
fasta_read_clean <- ape::read.dna(clean_wnv_input, format='fasta')
distance_wnv_clean <- dist.dna(fasta_read_clean)
wnv_hap_clean <- pegas::haplotype(fasta_read_clean)
wnv_hap_clean <- sort(wnv_hap_clean, what = "label")
wnv_clean_sub <- subset(wnv_hap_clean, maxfreq=Inf, maxna = Inf, na=c("N", "-"))
(net_clean <- pegas::haploNet(wnv_clean_sub))

#Haplotype network with:
#  568 haplotypes
#  80028 links
 # link lengths between 1 and 79 steps
#Still a lot of haplotypes... maybe filter out reads with any Ns? 


cleanest_seq <- readDNAStringSet("fasta/wnv_cleanest.fas")
length(cleanest_seq) #how many sequences do we have after all that filtering?
#157
length(cleanest_seq[[1]]) #length of first sequence in the multi FASTA file
  #10933, so it's the same length as the initial trimmed sequences 

#number of occurances of each character
alphabetFrequency(cleanest_seq, baseOnly=TRUE, collapse=TRUE) #total 
#   A      C      G      T  other ### other in this might also be talking about '-'s
#469385 380987 492752 370785   2572

freqs_cleanest <- alphabetFrequency(DNAStringSet(cleanest_seq[!is.na(cleanest_seq)]), baseOnly=TRUE) # number of bases by sequence 
head(freqs_cleanest)
BrowseSeqs(cleanest_seq, highlight=0) #visualize sequences in internet browser.'other' in this might also be talking about '-'s
 
cleanest_wnv_input <- "fasta/wnv_cleanest.fas"
fasta_read_cleanest <- ape::read.dna(cleanest_wnv_input, format='fasta')
distance_wnv_cleanest <- dist.dna(fasta_read_cleanest)
wnv_hap_cleanest <- pegas::haplotype(fasta_read_cleanest)
wnv_hap_cleanest <- sort(wnv_hap_cleanest, what = "label")
net_cleanest <- pegas::haploNet(wnv_hap_cleanest)
net_cleanest
#Haplotype network with:
# 157 haplotypes
# 9138 links
 # link lengths between 1 and 97 steps
class(wnv_hap_cleanest)

hap_cleanest <-with(
  stack(setNames(attr(wnv_hap_cleanest, "index"), rownames(wnv_hap_cleanest))),
table(hap=ind, pop=rownames(fasta_read_cleanest)[values]))


plot(net_cleanest, size=1, scale.ratio=0.2, pie=hap_cleanest, labels=NULL)
legend(-8, 0, colnames(hap_cleanest), col=rainbow(ncol(hap_cleanest)), pch=19, ncol=2)

haplnet <- haploNet(wnv_hap_cleanest)
plot(haplnet, size=1, scale.ratio=0.2, pie= wnv_hap_cleanest)

###PCA on just snp data to calculate principle varaince and group individuals. 
library(adegenet)
library(spdep)
library(dartR) ## One good lesson. If you develope a package be sure to include all the dependencies in the installation you twat
library(csv)

obj <- fasta2genlight("fasta/wnv_cleanest.fas", chunk=10, parallel = F) ##Create genlight object which conserves polymorphic sites 
obj
 # /// GENLIGHT OBJECT /////////
 # 
 # // 157 genotypes,  1,253 binary SNPs, size: 274.4 Kb
 # 12 (0.01 %) missing data
 # 
 # // Basic content
 #   @gen: list of 157 SNPbin
 #   @ploidy: ploidy of each individual  (range: 1-1)
 # 
 # // Optional content
 #   @ind.names:  157 individual labels
 #   @loc.all:  1253 alleles
 #   @position: integer storing positions of the SNPs
 #   @other: a list containing: elements without names
obj.gein <- gl2gi(obj, v=1) #3Convert to a geind obj usinf dartr
x.wnv <- tab(obj.gein, freq=TRUE, NA.method="mean") #Get rid of missing values otherwise the pca won't run
class(x.wnv)
wnv_df <- as.data.frame(x.wnv)
wnv_df <- add_rownames(wnv_df, "sequence_id")
write.csv(wnv_df, "C:/Users/Rebecca/Desktop/Homework 5/NSCI535-westnile-omics/wnv_test.csv")

library(ggfortify)
library(ggplot2)
library(ade4)
library(adegraphics)
wnv_df_test <- read.csv("wnv_test1.csv")
wnv_df_trial <- wnv_df_test[c(3:157)]
wnv_df_trial <- as.data.frame(wnv_df_trial)
pca.wnv <- dudi.pca(wnv_df_trial)

pop_group <- as.factor(wnv_df_test$Population)
s.class(pca.wnv$li, fac=pop_group, col=transp(funky(15)))

##ggplot of top three sampling counties
autoplot(prcomp(wnv_df_trial), data = wnv_df_test, colour = 'Population', frame=TRUE, frame.type='norm')

mypca <- glPca(obj)
myCol <- colorplot(mypca$scores,mypca$scores, transp=TRUE, cex=4, main= "West Nile Virus PCA")
abline(h=0,v=0, col="grey")
add.scatter.eig(mypca$eig[1:40],2,1,2, posi="topright", inset=.05, ratio=.3)


pca.wnv <- dudi.pca(wnv_df_trial, center=TRUE, scale=FALSE)
pop_groups <- as.factor(wnv_df_test$Population)
s.label(pca.wnv$li)
s.class(pca.wnv$li, fac = pop_groups, col= funky(15), facets = pop_groups)


##What does it look like with the "clean dataset?"

obj2 <- fasta2genlight("fasta/clear_wnv_clean.fas", chunk=10, parallel = F) ##Create genlight object which conserves polymorphic sites 
obj2

obj.gein2 <- gl2gi(obj2, v=1) #3Convert to a geind obj usinf dartr
x.wnv2 <- tab(obj.gein2, freq=TRUE, NA.method="mean") #Get rid of missing values otherwise the pca won't run
class(x.wnv2)
wnv_df2 <- as.data.frame(x.wnv2)
wnv_df2 <- add_rownames(wnv_df2, "sequence_id")
write.csv(wnv_df2, "wnv_test_2.csv")

wnv_df_test2 <- read.csv("wnv_test_2.csv")
wnv_df_trial2 <- wnv_df_test2[c(3:157)]
wnv_df_trial2 <- as.data.frame(wnv_df_trial2)

autoplot(prcomp(wnv_df_trial2), data = wnv_df_test2, colour = 'population', frame=TRUE, frame.type='norm') +theme_classic()


pca.wnv.test <- dudi.pca(wnv_df_trial2, center=TRUE, scale=FALSE)
pop_group <- as.factor(wnv_df_test2$population)
s.label(pca.wnv.test$li,  facets = pop_group)
s.class(pca.wnv.test$li, fac = pop_group, col= funky(15), repel=TRUE)



```



